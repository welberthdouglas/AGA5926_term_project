{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T06:43:28.306184Z",
     "start_time": "2021-08-03T06:43:23.084480Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, Add, Dense\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from astropy.io import fits\n",
    "\n",
    "from utils import download_data\n",
    "from config import *\n",
    "from objects import COORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T06:43:59.053204Z",
     "start_time": "2021-08-03T06:43:28.308115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading legacy survey data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:13<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "establishing connection to splus ...\n",
      "Login: welberth\n",
      "Password: ········\n",
      "downloading splus data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:04<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_data(COORDS,SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T05:39:35.716111Z",
     "start_time": "2021-08-03T05:39:35.686799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((3, 128, 128), (3, 256, 256))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(fits.open(f'data/fits/RA{ra}_DEC{dec}_SPLUS.fits')[0].data.shape,fits.open(f'data/fits/RA{ra}_DEC{dec}_LEGACY.fits')[0].data.shape) for ra,dec in COORDS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T05:42:23.223100Z",
     "start_time": "2021-08-03T05:42:23.220778Z"
    }
   },
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T00:49:30.526212Z",
     "start_time": "2021-08-03T00:49:30.478941Z"
    }
   },
   "outputs": [],
   "source": [
    "def residual_block(x):\n",
    "    \"\"\"\n",
    "    Residual block\n",
    "    \"\"\"\n",
    "    filters = [64, 64]\n",
    "    kernel_size = 3\n",
    "    strides = 1\n",
    "    padding = \"same\"\n",
    "    momentum = 0.8\n",
    "    activation = \"relu\"\n",
    "\n",
    "    res = Conv2D(filters=filters[0], kernel_size=kernel_size, strides=strides, padding=padding)(x)\n",
    "    res = Activation(activation=activation)(res)\n",
    "    res = BatchNormalization(momentum=momentum)(res)\n",
    "\n",
    "    res = Conv2D(filters=filters[1], kernel_size=kernel_size, strides=strides, padding=padding)(res)\n",
    "    res = BatchNormalization(momentum=momentum)(res)\n",
    "\n",
    "    # Add res and x\n",
    "    res = Add()([res, x])\n",
    "    return res\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    \"\"\"\n",
    "    Create a generator network using the hyperparameter values defined below\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    residual_blocks = 16\n",
    "    momentum = 0.8\n",
    "    input_shape = (128, 128, 3)\n",
    "\n",
    "    # Input Layer of the generator network\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Add the pre-residual block\n",
    "    gen1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='same', activation='relu')(input_layer)\n",
    "\n",
    "    # Add 16 residual blocks\n",
    "    res = residual_block(gen1)\n",
    "    for i in range(residual_blocks - 1):\n",
    "        res = residual_block(res)\n",
    "\n",
    "    # Add the post-residual block\n",
    "    gen2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(res)\n",
    "    gen2 = BatchNormalization(momentum=momentum)(gen2)\n",
    "\n",
    "    # Take the sum of the output from the pre-residual block(gen1) and the post-residual block(gen2)\n",
    "    gen3 = Add()([gen2, gen1])\n",
    "\n",
    "    # Add an upsampling block\n",
    "    gen4 = UpSampling2D(size=2)(gen3)\n",
    "    gen4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen4)\n",
    "    gen4 = Activation('relu')(gen4)\n",
    "\n",
    "   ## Add another upsampling block\n",
    "   #gen5 = UpSampling2D(size=2)(gen4)\n",
    "   #gen5 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen5)\n",
    "   #gen5 = Activation('relu')(gen5)\n",
    "\n",
    "    # Output convolution layer\n",
    "    gen5 = Conv2D(filters=3, kernel_size=9, strides=1, padding='same')(gen4)\n",
    "    output = Activation('tanh')(gen5)\n",
    "\n",
    "    # Keras model\n",
    "    model = Model(inputs=[input_layer], outputs=[output], name='generator')\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    \"\"\"\n",
    "    Create a discriminator network using the hyperparameter values defined below\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    leakyrelu_alpha = 0.2\n",
    "    momentum = 0.8\n",
    "    input_shape = (256, 256, 3)\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Add the first convolution block\n",
    "    dis1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n",
    "    dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n",
    "\n",
    "    # Add the 2nd convolution block\n",
    "    dis2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(dis1)\n",
    "    dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n",
    "    dis2 = BatchNormalization(momentum=momentum)(dis2)\n",
    "\n",
    "    # Add the third convolution block\n",
    "    dis3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(dis2)\n",
    "    dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n",
    "    dis3 = BatchNormalization(momentum=momentum)(dis3)\n",
    "\n",
    "    # Add the fourth convolution block\n",
    "    dis4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same')(dis3)\n",
    "    dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n",
    "    dis4 = BatchNormalization(momentum=0.8)(dis4)\n",
    "\n",
    "    # Add the fifth convolution block\n",
    "    dis5 = Conv2D(256, kernel_size=3, strides=1, padding='same')(dis4)\n",
    "    dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n",
    "    dis5 = BatchNormalization(momentum=momentum)(dis5)\n",
    "\n",
    "    # Add the sixth convolution block\n",
    "    dis6 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same')(dis5)\n",
    "    dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n",
    "    dis6 = BatchNormalization(momentum=momentum)(dis6)\n",
    "\n",
    "    # Add the seventh convolution block\n",
    "    dis7 = Conv2D(filters=512, kernel_size=3, strides=1, padding='same')(dis6)\n",
    "    dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n",
    "    dis7 = BatchNormalization(momentum=momentum)(dis7)\n",
    "\n",
    "    # Add the eight convolution block\n",
    "    dis8 = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(dis7)\n",
    "    dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n",
    "    dis8 = BatchNormalization(momentum=momentum)(dis8)\n",
    "\n",
    "    # Add a dense layer\n",
    "    dis9 = Dense(units=1024)(dis8)\n",
    "    dis9 = LeakyReLU(alpha=0.2)(dis9)\n",
    "\n",
    "    # Last dense layer - for classification\n",
    "    output = Dense(units=1, activation='sigmoid')(dis9)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=[output], name='discriminator')\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_vgg():\n",
    "    \"\"\"\n",
    "    Build VGG network to extract image features\n",
    "    \"\"\"\n",
    "    input_shape = (256, 256, 3)\n",
    "\n",
    "    # Load a pre-trained VGG19 model trained on 'Imagenet' dataset\n",
    "    vgg = VGG19(weights=\"imagenet\")\n",
    "    vgg.outputs = [vgg.layers[9].output]\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Extract features\n",
    "    features = vgg(input_layer)\n",
    "\n",
    "    # Create a Keras model\n",
    "    model = Model(inputs=[input_layer], outputs=[features])\n",
    "    return model\n",
    "\n",
    "\n",
    "def sample_images(data_dir, batch_size, high_resolution_shape, low_resolution_shape):\n",
    "    # Make a list of all images inside the data directory\n",
    "    all_images = glob.glob(data_dir)\n",
    "\n",
    "    # Choose a random batch of images\n",
    "    images_batch = np.random.choice(all_images, size=batch_size)\n",
    "\n",
    "    low_resolution_images = []\n",
    "    high_resolution_images = []\n",
    "\n",
    "    for img in images_batch:\n",
    "        # Get an ndarray of the current image\n",
    "        img1 = imread(img, mode='RGB')\n",
    "        img1 = img1.astype(np.float32)\n",
    "\n",
    "        # Resize the image\n",
    "        img1_high_resolution = imresize(img1, high_resolution_shape)\n",
    "        img1_low_resolution = imresize(img1, low_resolution_shape)\n",
    "\n",
    "        # Do a random horizontal flip\n",
    "        if np.random.random() < 0.5:\n",
    "            img1_high_resolution = np.fliplr(img1_high_resolution)\n",
    "            img1_low_resolution = np.fliplr(img1_low_resolution)\n",
    "\n",
    "        high_resolution_images.append(img1_high_resolution)\n",
    "        low_resolution_images.append(img1_low_resolution)\n",
    "\n",
    "    # Convert the lists to Numpy NDArrays\n",
    "    return np.array(high_resolution_images), np.array(low_resolution_images)\n",
    "\n",
    "\n",
    "def save_images(low_resolution_image, original_image, generated_image, path):\n",
    "    \"\"\"\n",
    "    Save low-resolution, high-resolution(original) and\n",
    "    generated high-resolution images in a single image\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 3, 1)\n",
    "    ax.imshow(low_resolution_image)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Low-resolution\")\n",
    "\n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    ax.imshow(original_image)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Original\")\n",
    "\n",
    "    ax = fig.add_subplot(1, 3, 3)\n",
    "    ax.imshow(generated_image)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Generated\")\n",
    "\n",
    "    plt.savefig(path)\n",
    "\n",
    "\n",
    "def write_log(callback, name, value, batch_no):\n",
    "    \"\"\"\n",
    "    Write scalars to Tensorboard\n",
    "    \"\"\"\n",
    "    summary = tf.Summary()\n",
    "    summary_value = summary.value.add()\n",
    "    summary_value.simple_value = value\n",
    "    summary_value.tag = name\n",
    "    callback.writer.add_summary(summary, batch_no)\n",
    "    callback.writer.flush()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_dir = \"data/img_align_celeba/*.*\"\n",
    "    epochs = 30000\n",
    "    batch_size = 1\n",
    "    mode = 'predict'\n",
    "\n",
    "    # Shape of low-resolution and high-resolution images\n",
    "    low_resolution_shape = (64, 64, 3)\n",
    "    high_resolution_shape = (256, 256, 3)\n",
    "\n",
    "    # Common optimizer for all networks\n",
    "    common_optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "    if mode == 'train':\n",
    "        # Build and compile VGG19 network to extract features\n",
    "        vgg = build_vgg()\n",
    "        vgg.trainable = False\n",
    "        vgg.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the discriminator network\n",
    "        discriminator = build_discriminator()\n",
    "        discriminator.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator network\n",
    "        generator = build_generator()\n",
    "\n",
    "        \"\"\"\n",
    "        Build and compile the adversarial model\n",
    "        \"\"\"\n",
    "\n",
    "        # Input layers for high-resolution and low-resolution images\n",
    "        input_high_resolution = Input(shape=high_resolution_shape)\n",
    "        input_low_resolution = Input(shape=low_resolution_shape)\n",
    "\n",
    "        # Generate high-resolution images from low-resolution images\n",
    "        generated_high_resolution_images = generator(input_low_resolution)\n",
    "\n",
    "        # Extract feature maps of the generated images\n",
    "        features = vgg(generated_high_resolution_images)\n",
    "\n",
    "        # Make the discriminator network as non-trainable\n",
    "        discriminator.trainable = False\n",
    "\n",
    "        # Get the probability of generated high-resolution images\n",
    "        probs = discriminator(generated_high_resolution_images)\n",
    "\n",
    "        # Create and compile an adversarial model\n",
    "        adversarial_model = Model([input_low_resolution, input_high_resolution], [probs, features])\n",
    "        adversarial_model.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=common_optimizer)\n",
    "\n",
    "        # Add Tensorboard\n",
    "        tensorboard = TensorBoard(log_dir=\"logs/\".format(time.time()))\n",
    "        tensorboard.set_model(generator)\n",
    "        tensorboard.set_model(discriminator)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch:{}\".format(epoch))\n",
    "\n",
    "            \"\"\"\n",
    "            Train the discriminator network\n",
    "            \"\"\"\n",
    "\n",
    "            # Sample a batch of images\n",
    "            high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=batch_size,\n",
    "                                                                          low_resolution_shape=low_resolution_shape,\n",
    "                                                                          high_resolution_shape=high_resolution_shape)\n",
    "            # Normalize images\n",
    "            high_resolution_images = high_resolution_images / 127.5 - 1.\n",
    "            low_resolution_images = low_resolution_images / 127.5 - 1.\n",
    "\n",
    "            # Generate high-resolution images from low-resolution images\n",
    "            generated_high_resolution_images = generator.predict(low_resolution_images)\n",
    "\n",
    "            # Generate batch of real and fake labels\n",
    "            real_labels = np.ones((batch_size, 16, 16, 1))\n",
    "            fake_labels = np.zeros((batch_size, 16, 16, 1))\n",
    "\n",
    "            # Train the discriminator network on real and fake images\n",
    "            d_loss_real = discriminator.train_on_batch(high_resolution_images, real_labels)\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_high_resolution_images, fake_labels)\n",
    "\n",
    "            # Calculate total discriminator loss\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            print(\"d_loss:\", d_loss)\n",
    "\n",
    "            \"\"\"\n",
    "            Train the generator network\n",
    "            \"\"\"\n",
    "\n",
    "            # Sample a batch of images\n",
    "            high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=batch_size,\n",
    "                                                                          low_resolution_shape=low_resolution_shape,\n",
    "                                                                          high_resolution_shape=high_resolution_shape)\n",
    "            # Normalize images\n",
    "            high_resolution_images = high_resolution_images / 127.5 - 1.\n",
    "            low_resolution_images = low_resolution_images / 127.5 - 1.\n",
    "\n",
    "            # Extract feature maps for real high-resolution images\n",
    "            image_features = vgg.predict(high_resolution_images)\n",
    "\n",
    "            # Train the generator network\n",
    "            g_loss = adversarial_model.train_on_batch([low_resolution_images, high_resolution_images],\n",
    "                                             [real_labels, image_features])\n",
    "\n",
    "            print(\"g_loss:\", g_loss)\n",
    "\n",
    "            # Write the losses to Tensorboard\n",
    "            write_log(tensorboard, 'g_loss', g_loss[0], epoch)\n",
    "            write_log(tensorboard, 'd_loss', d_loss[0], epoch)\n",
    "\n",
    "            # Sample and save images after every 100 epochs\n",
    "            if epoch % 100 == 0:\n",
    "                high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=batch_size,\n",
    "                                                                              low_resolution_shape=low_resolution_shape,\n",
    "                                                                              high_resolution_shape=high_resolution_shape)\n",
    "                # Normalize images\n",
    "                high_resolution_images = high_resolution_images / 127.5 - 1.\n",
    "                low_resolution_images = low_resolution_images / 127.5 - 1.\n",
    "\n",
    "                generated_images = generator.predict_on_batch(low_resolution_images)\n",
    "\n",
    "                for index, img in enumerate(generated_images):\n",
    "                    save_images(low_resolution_images[index], high_resolution_images[index], img,\n",
    "                                path=\"results/img_{}_{}\".format(epoch, index))\n",
    "\n",
    "        # Save models\n",
    "        generator.save_weights(\"generator.h5\")\n",
    "        discriminator.save_weights(\"discriminator.h5\")\n",
    "\n",
    "    if mode == 'predict':\n",
    "        # Build and compile the discriminator network\n",
    "        discriminator = build_discriminator()\n",
    "\n",
    "        # Build the generator network\n",
    "        generator = build_generator()\n",
    "\n",
    "        # Load models\n",
    "        generator.load_weights(\"generator.h5\")\n",
    "        discriminator.load_weights(\"discriminator.h5\")\n",
    "\n",
    "        # Get 10 random images\n",
    "        high_resolution_images, low_resolution_images = sample_images(data_dir=data_dir, batch_size=10,\n",
    "                                                                      low_resolution_shape=low_resolution_shape,\n",
    "                                                                      high_resolution_shape=high_resolution_shape)\n",
    "        # Normalize images\n",
    "        high_resolution_images = high_resolution_images / 127.5 - 1.\n",
    "        low_resolution_images = low_resolution_images / 127.5 - 1.\n",
    "\n",
    "        # Generate high-resolution images from low-resolution images\n",
    "        generated_images = generator.predict_on_batch(low_resolution_images)\n",
    "\n",
    "        # Save images\n",
    "        for index, img in enumerate(generated_images):\n",
    "            save_images(low_resolution_images[index], high_resolution_images[index], img,\n",
    "                        path=\"results/gen_{}\".format(index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aga",
   "language": "python",
   "name": "aga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
