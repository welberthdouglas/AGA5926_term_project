{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T23:49:19.117870Z",
     "start_time": "2021-08-15T23:49:19.106265Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, Add, Dense\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from astropy.io import fits\n",
    "\n",
    "from config import *\n",
    "from objects import COORDS\n",
    "from utils import (download_data,\n",
    "                   sample_fits,\n",
    "                   data_augmentation,\n",
    "                   normalize,\n",
    "                   fits_processing,\n",
    "                   fits2images,\n",
    "                   save_images)\n",
    "\n",
    "\n",
    "np.random.seed(SEED)\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T15:09:23.943103Z",
     "start_time": "2021-08-14T14:47:41.211551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "establishing connection to splus ...\n",
      "Login: welberth\n",
      "Password: ········\n",
      "downloading splus data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 250/250 [05:13<00:00,  1.26s/it]\n",
      "100%|███████████████████████████████████████████| 25/25 [00:31<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading legacy survey data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 250/250 [14:34<00:00,  3.50s/it]\n",
      "100%|███████████████████████████████████████████| 25/25 [01:12<00:00,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_data(COORDS,DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T18:12:15.637155Z",
     "start_time": "2021-08-14T18:11:54.633226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving training images ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 250/250 [00:17<00:00, 14.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving validation images ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [00:01<00:00, 14.12it/s]\n"
     ]
    }
   ],
   "source": [
    "fits2images(DATA_DIR,IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T01:20:30.750770Z",
     "start_time": "2021-08-15T01:20:30.748455Z"
    }
   },
   "source": [
    "# GAN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T05:42:23.223100Z",
     "start_time": "2021-08-03T05:42:23.220778Z"
    }
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T23:30:49.311601Z",
     "start_time": "2021-08-15T23:30:49.302082Z"
    }
   },
   "outputs": [],
   "source": [
    "def residual_block(x):\n",
    "    \"\"\"\n",
    "    Residual block\n",
    "    \"\"\"\n",
    "    filters = [64, 64]\n",
    "    kernel_size = 3\n",
    "    strides = 1\n",
    "    padding = \"same\"\n",
    "    momentum = 0.8\n",
    "    activation = \"relu\"\n",
    "\n",
    "    res = Conv2D(filters=filters[0], kernel_size=kernel_size, strides=strides, padding=padding)(x)\n",
    "    res = Activation(activation=activation)(res)\n",
    "    res = BatchNormalization(momentum=momentum)(res)\n",
    "\n",
    "    res = Conv2D(filters=filters[1], kernel_size=kernel_size, strides=strides, padding=padding)(res)\n",
    "    res = BatchNormalization(momentum=momentum)(res)\n",
    "\n",
    "    # Add res and x\n",
    "    res = Add()([res, x])\n",
    "    return res\n",
    "\n",
    "\n",
    "def build_generator():\n",
    "    \"\"\"\n",
    "    Create a generator network using the hyperparameter values defined below\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    residual_blocks = 16\n",
    "    momentum = 0.8\n",
    "    input_shape = (128, 128, 3)\n",
    "\n",
    "    # Input Layer of the generator network\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Add the pre-residual block\n",
    "    gen1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='same', activation='relu')(input_layer)\n",
    "\n",
    "    # Add 16 residual blocks\n",
    "    res = residual_block(gen1)\n",
    "    for i in range(residual_blocks - 1):\n",
    "        res = residual_block(res)\n",
    "\n",
    "    # Add the post-residual block\n",
    "    gen2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(res)\n",
    "    gen2 = BatchNormalization(momentum=momentum)(gen2)\n",
    "\n",
    "    # Take the sum of the output from the pre-residual block(gen1) and the post-residual block(gen2)\n",
    "    gen3 = Add()([gen2, gen1])\n",
    "\n",
    "    # Add an upsampling block\n",
    "    gen4 = UpSampling2D(size=2)(gen3)\n",
    "    gen4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen4)\n",
    "    gen4 = Activation('relu')(gen4)\n",
    "\n",
    "    # Output convolution layer\n",
    "    gen5 = Conv2D(filters=3, kernel_size=9, strides=1, padding='same')(gen4)\n",
    "    output = Activation('tanh')(gen5)\n",
    "\n",
    "    return Model(inputs=[input_layer], outputs=[output], name='generator')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T23:30:49.324288Z",
     "start_time": "2021-08-15T23:30:49.313471Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    \"\"\"\n",
    "    Create a discriminator network using the hyperparameter values defined below\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    leakyrelu_alpha = 0.2\n",
    "    momentum = 0.8\n",
    "    input_shape = (256, 256, 3)\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Add the first convolution block\n",
    "    dis1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n",
    "    dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n",
    "\n",
    "    # Add the 2nd convolution block\n",
    "    dis2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(dis1)\n",
    "    dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n",
    "    dis2 = BatchNormalization(momentum=momentum)(dis2)\n",
    "\n",
    "    # Add the third convolution block\n",
    "    dis3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(dis2)\n",
    "    dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n",
    "    dis3 = BatchNormalization(momentum=momentum)(dis3)\n",
    "\n",
    "    # Add the fourth convolution block\n",
    "    dis4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same')(dis3)\n",
    "    dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n",
    "    dis4 = BatchNormalization(momentum=0.8)(dis4)\n",
    "\n",
    "    # Add the fifth convolution block\n",
    "    dis5 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(dis4)\n",
    "    dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n",
    "    dis5 = BatchNormalization(momentum=momentum)(dis5)\n",
    "\n",
    "    # Add the sixth convolution block\n",
    "    dis6 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same')(dis5)\n",
    "    dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n",
    "    dis6 = BatchNormalization(momentum=momentum)(dis6)\n",
    "\n",
    "    # Add the seventh convolution block\n",
    "    dis7 = Conv2D(filters=512, kernel_size=3, strides=1, padding='same')(dis6)\n",
    "    dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n",
    "    dis7 = BatchNormalization(momentum=momentum)(dis7)\n",
    "\n",
    "    # Add the eight convolution block\n",
    "    dis8 = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(dis7)\n",
    "    dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n",
    "    dis8 = BatchNormalization(momentum=momentum)(dis8)\n",
    "\n",
    "    # Add a dense layer\n",
    "    dis9 = Dense(units=1024)(dis8)\n",
    "    dis9 = LeakyReLU(alpha=0.2)(dis9)\n",
    "\n",
    "    # Last dense layer - for classification\n",
    "    output = Dense(units=1, activation='sigmoid')(dis9)\n",
    "    \n",
    "    discriminator = Model(inputs=[input_layer], outputs=[output], name='discriminator')\n",
    "    discriminator.compile(loss='mse', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG - Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T23:30:49.330515Z",
     "start_time": "2021-08-15T23:30:49.326851Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_vgg():\n",
    "    \"\"\"\n",
    "    Build VGG network to extract image features\n",
    "    \"\"\"\n",
    "\n",
    "    # Load a pre-trained VGG19 model trained on 'Imagenet' dataset\n",
    "    vgg = VGG19(weights=\"imagenet\", include_top=False, input_shape=(256,256,3))\n",
    "    vgg.trainable = False\n",
    "    \n",
    "    model_vgg = Model(inputs=vgg.inputs, outputs=vgg.layers[9].output)\n",
    "    model_vgg.compile(loss='mse', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "    return model_vgg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T23:30:50.170604Z",
     "start_time": "2021-08-15T23:30:50.165810Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def build_adversarial_model(generator,discriminator,vgg):\n",
    "    \n",
    "    # Inputs\n",
    "    input_high_resolution = Input(shape=(256,256,3))\n",
    "    input_low_resolution = Input(shape=(128,128,3))\n",
    "    \n",
    "    generated_high_resolution_images = generator(input_low_resolution)\n",
    "    features = vgg(generated_high_resolution_images)\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    probs = discriminator(generated_high_resolution_images)\n",
    "    \n",
    "    # Create and compile an adversarial model\n",
    "    adversarial_model = Model([input_low_resolution, input_high_resolution], [probs, features])\n",
    "    adversarial_model.compile(loss=['binary_crossentropy', 'mse'],\n",
    "                              loss_weights=[1e-3, 1], \n",
    "                              optimizer=Adam(0.0002, 0.5))\n",
    "    \n",
    "    return adversarial_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T23:48:52.053754Z",
     "start_time": "2021-08-15T23:48:52.049340Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(data_dir:str = DATA_DIR+\"train/\",\n",
    "             train_size:float = TRAIN_SIZE,\n",
    "             augmentation_factor:int = AUGMENTATION_FACTOR)->tuple:\n",
    "    \n",
    "    # load fits\n",
    "    train_splus_fits, train_legacy_fits,_ = sample_fits(data_dir,TRAIN_SIZE)\n",
    "    \n",
    "    # asinh shrink and normalize\n",
    "    train_splus_images,train_legacy_images = fits_processing(train_splus_fits),fits_processing(train_legacy_fits)\n",
    "    \n",
    "    # perform data augmentation\n",
    "    augmented_data = (data_augmentation(train_splus_images, augmentation_factor=augmentation_factor),\n",
    "                      data_augmentation(train_legacy_images, augmentation_factor=augmentation_factor))\n",
    "    \n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T17:43:51.957408Z",
     "start_time": "2021-08-15T17:43:51.954835Z"
    }
   },
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T23:30:52.330299Z",
     "start_time": "2021-08-15T23:30:52.319776Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_GAN(generator,\n",
    "              discriminator,\n",
    "              vgg,\n",
    "              adversarial_model,\n",
    "              data, \n",
    "              epochs,\n",
    "              batch_size,\n",
    "              summary_writer):\n",
    "    \n",
    "    batches_per_epoch = int(data[0].shape[0]/batch_size)\n",
    "    step = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch:{epoch}\")\n",
    "        for i in range(batches_per_epoch):\n",
    "    \n",
    "            \"\"\"\n",
    "            Train the discriminator network\n",
    "            \"\"\"\n",
    "            # get a batch of images\n",
    "            splus_images = data[0][i * batch_size:(i + 1) * batch_size]\n",
    "            legacy_images = data[1][i * batch_size:(i + 1) * batch_size]\n",
    "        \n",
    "            # Generate high-resolution images from low-resolution images\n",
    "            generated_images = generator.predict(splus_images)\n",
    "        \n",
    "            # Generate batch of real and fake labels\n",
    "            SR_labels = np.ones((BATCH_SIZE, 16, 16, 1))\n",
    "            LR_labels = np.zeros((BATCH_SIZE, 16, 16, 1))\n",
    "        \n",
    "            # Train the discriminator network on LR and SR images\n",
    "            d_loss_real = discriminator.train_on_batch(legacy_images, SR_labels)\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images, LR_labels)\n",
    "        \n",
    "            # Calculate total discriminator loss\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            print(\"d_loss:\", d_loss)\n",
    "        \n",
    "            \"\"\"\n",
    "            Train the generator network\n",
    "            \"\"\"\n",
    "        \n",
    "            # Extract feature maps for real high-resolution images\n",
    "            image_features = vgg.predict(legacy_images)\n",
    "        \n",
    "            # Train the generator network\n",
    "            g_loss = adversarial_model.train_on_batch([splus_images, legacy_images],\n",
    "                                             [SR_labels, image_features])\n",
    "        \n",
    "            print(\"g_loss:\", g_loss)\n",
    "        \n",
    "            # Write the losses to Tensorboard\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('generator_loss', g_loss[0], step=step)\n",
    "                tf.summary.scalar('disciminator_loss', d_loss[0], step=step)\n",
    "                summary_writer.flush()\n",
    "                \n",
    "            step +=1\n",
    "        \n",
    "        # Sample and save validation images after every 100 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            splus_fits, legacy_fits,_ = sample_fits(DATA_DIR+\"validation/\",3)\n",
    "            \n",
    "            # Asinh Shrink and Normalize images\n",
    "            low_resolution_images = fits_processing(splus_fits)\n",
    "            high_resolution_images = fits_processing(legacy_fits)\n",
    "    \n",
    "            generated_images = generator.predict_on_batch(low_resolution_images)\n",
    "            generated_images = normalize(generated_images)\n",
    "    \n",
    "            for index, img in enumerate(generated_images):\n",
    "                save_images(low_resolution_images[index], high_resolution_images[index], img,path=\"results/img_{}_{}\".format(epoch, index))\n",
    "        \n",
    "        # Save model checkpoint after 1000 epochs\n",
    "        if epoch % 1000 == 0:\n",
    "            generator.save_weights(\"generator.h5\")\n",
    "            discriminator.save_weights(\"discriminator.h5\")\n",
    "            \n",
    "    # Save final models\n",
    "    generator.save_weights(\"generator.h5\")\n",
    "    discriminator.save_weights(\"discriminator.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T23:59:35.921173Z",
     "start_time": "2021-08-15T23:59:35.745766Z"
    }
   },
   "outputs": [],
   "source": [
    "rm -r logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T00:34:16.824855Z",
     "start_time": "2021-08-16T00:34:13.127365Z"
    }
   },
   "outputs": [],
   "source": [
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T00:35:08.553001Z",
     "start_time": "2021-08-16T00:35:05.814857Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data.pkl','wb') as f:\n",
    "     pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T23:58:27.557390Z",
     "start_time": "2021-08-15T23:58:24.995258Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg = build_vgg()\n",
    "discriminator = build_discriminator()\n",
    "generator = build_generator()\n",
    "adversarial_model = build_adversarial_model(generator,discriminator,vgg)\n",
    "\n",
    "try:\n",
    "    with open('data.pkl','rb') as f:\n",
    "         data = pickle.load(f)\n",
    "except:\n",
    "    print(\"data.pkl not found, trying to preprocess data from raw fits ...\")\n",
    "    data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T23:31:06.298673Z",
     "start_time": "2021-08-15T23:31:02.742919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {dir_writer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-15T23:43:31.229575Z",
     "start_time": "2021-08-15T23:31:38.715597Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-15 20:31:38.771111: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_loss: [0.35696186 0.40996094]\n",
      "g_loss: [103.07905578613281, 0.6302959322929382, 103.07841491699219]\n",
      "d_loss: [0.29841691 0.45761719]\n",
      "g_loss: [56.7684211730957, 0.7570024728775024, 56.767662048339844]\n",
      "d_loss: [0.21541672 0.66210938]\n",
      "g_loss: [23.55597686767578, 0.7912254333496094, 23.555185317993164]\n",
      "d_loss: [0.19600723 0.63984376]\n",
      "g_loss: [14.27336311340332, 1.879446029663086, 14.271482467651367]\n",
      "d_loss: [0.07605557 0.93535158]\n",
      "g_loss: [15.041994094848633, 3.776254177093506, 15.038217544555664]\n",
      "d_loss: [0.02406871 0.98964843]\n",
      "g_loss: [15.123529434204102, 5.466404438018799, 15.118062019348145]\n",
      "d_loss: [0.01207479 1.        ]\n",
      "g_loss: [15.074897766113281, 6.48482608795166, 15.068412780761719]\n",
      "d_loss: [0.00474694 1.        ]\n",
      "g_loss: [14.75987434387207, 8.487457275390625, 14.751385688781738]\n",
      "Epoch:1\n",
      "d_loss: [0.00406523 1.        ]\n",
      "g_loss: [14.476346015930176, 11.729751586914062, 14.464614868164062]\n",
      "d_loss: [0.00380422 1.        ]\n",
      "g_loss: [14.045880317687988, 14.635702133178711, 14.031244277954102]\n",
      "d_loss: [0.00475663 1.        ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s8/s_5x3bx56mj96hc3hktzpzdm0000gn/T/ipykernel_90123/1712342963.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           summary_writer = summary_writer)\n\u001b[0m",
      "\u001b[0;32m/var/folders/s8/s_5x3bx56mj96hc3hktzpzdm0000gn/T/ipykernel_90123/1691505933.py\u001b[0m in \u001b[0;36mtrain_GAN\u001b[0;34m(generator, discriminator, vgg, adversarial_model, data, epochs, batch_size, summary_writer)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# Train the generator network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             g_loss = adversarial_model.train_on_batch([splus_images, legacy_images],\n\u001b[0;32m---> 47\u001b[0;31m                                              [SR_labels, image_features])\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"g_loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/courses/AGA5926/aga/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1823\u001b[0m                                                     class_weight)\n\u001b[1;32m   1824\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1825\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1827\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/courses/AGA5926/aga/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/courses/AGA5926/aga/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/courses/AGA5926/aga/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/courses/AGA5926/aga/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/courses/AGA5926/aga/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/courses/AGA5926/aga/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_GAN(generator,\n",
    "          discriminator,\n",
    "          vgg,\n",
    "          adversarial_model,\n",
    "          data, \n",
    "          epochs = 30,\n",
    "          batch_size = BATCH_SIZE,\n",
    "          summary_writer = summary_writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aga",
   "language": "python",
   "name": "aga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
